<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[SpringBootLearning]]></title>
    <url>%2F2019%2F10%2F21%2FSpringBootLearning%2F</url>
    <content type="text"><![CDATA[SpringBootchapter 1 SpringSpring IoCIoC (Inversion Of Control) DI (Dependency Injection) 软件实体被动接受其依赖的其他组件被IoC容器注入 DL(Dependency Lookup) 当前软件实体主动去某个服务注册地查找其依赖的那些服务 使用Spring框架的JAVA应用通常都有一行”context.getBean()” 1context.getBean() 阶段一：注册和收集 通过XML或者java或者XML Schema的形式，定义一些bean，然后将其收集并注册进入IoC容器中。$\color{red}{就像pom.xml文件一样}$ 阶段二：分析和组装 一阶段完成后IoC容器中存在着许多相互独立的bean。通过分析这些bean之间的依赖关系，再组装他们，将一个bean所依赖的bean全部注入这个bean中。 JavaConfig任何一个标注了@Configuration的java配置类定义都是一个JavaConfig配置类 任何一个标注了@Bean的方法，其返回值作为一个bean定义注册到Spring的IoC容器。 以函数的调用形式来指示bean之间的依赖关系。 1234567891011@Configurationpublic class MockConfiguration&#123; @Bean public Service1 service1()&#123; return new Service1Imp1(service2()); &#125; @Bean public Service2 service2()&#123; return new Service2Imp1(; &#125;&#125; chapter 2 SpringBoot的工作机制1.基本结构123456@SpringApplicationpublic class DemoApplication&#123; public static void main(String args[])&#123; SpringApplication.run(DemoApplication.class, args); &#125;&#125; 2.@SpringBootApplication@SpringBootApplication等价于： @Target @Retention @Documented @Inherited @Configuration @EnableAutoConfiguration @ComponentScan @Configuration定义一个配置类的IoC容器 @EnableAutoConfiguration借助@Import的支持，收集和注册特定场景相关的bean定义 等价于@Import(EnableAutoConfigurationImportSelector.class) 借助EnableAutoConfigurationImportSelector.class，帮助SpringBoot应用将所有符合条件的@Configuration配置加载到当前的IoC容器之中，再借助工具类SpringFactoriesLoader的支持，@EnableAutoConfiguration“智能”地自动配置功效。 SpringFactoriesLoader根据类名查找对应的一组@Configuration 3.SpringApplication其执行流程如下： 创建一个SpringApplication的对象实例，调用其run方法。 根据classpath中的特征类来创建一个对应应用（如web）的ApplicationContext类 使用SpringFactoriesLoader在classpath中查找并加载所有可用的ApplicationContextInitializer和ApplicationListener 初始化完成后，对所有SpringApplicationRunListener调用其started()方法。 创建并配置环境 对所有SpringApplicationRunListener调用environmentPrepared()。 创建某一类的ApplicationContext，并将之前的环境给其使用 调用所有的AppicationContextInitializer的initialize(applicationContext)方法来对已经创建好的ApplicationContext进一步处理 调用所有的SpringApplicationRunListener的contextPrepared()方法 将之前通过@EnableAutoConfiguration获得的所有配置信息和IoC容器加入ApplicationContext中 调用所有的SpringApplicationRunListener的contextLoaded()方法 调用ApplicationContext的refresh()方法 查找ApplicationContext中是否注册有CommandLineRunner，如果有就遍历执行他们 完成！调用SpringApplicationRunListener的finished方法 chapter 3 spring-boot-starter ​ ​]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HMM马尔科夫链]]></title>
    <url>%2F2019%2F08%2F18%2FHMM%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E9%93%BE%2F</url>
    <content type="text"><![CDATA[介绍​ 隐含马尔科夫模型包括一个状态集合$Q={q_1,q_2,…,q_N}$以及观测集合$V={v_1,v_2,…,v_M}$。其中$N$和$M$分别是可能的状态数和观测数。 ​ $I$是长度为$T$的状态序列$I=(i_1,i_2,…i_T)$，$O$是对应的观测序列$O=(o_1,o_2,…,o_T)$。 ​ $A$是状态转移矩阵，表示由一个状态转移到另一个状态的概率。$$A_{ij}=P(i_{t+1}=q_j|i_t=q_{t+1})$$​ $B$是观测矩阵，也被称作发射矩阵,表示由一个状态生成一个观测对应的概率：$$B_{jk}=P(o_t=v_k|i_t=q_j)$$​ $\pi$为初始状态向量，$\pi_i=P(i_1=q_i)$。 ​ 一个HMM模型由上述三者构成，$$\lambda = (A,B,\pi)$$​ ​ HMM模型是一个生成式模型(Generative Model)，目的是生成状态序列$I$和观测序列$O$的联合分布$f(O,I)$。 ​ HMM存在三个基本问题： 计算概率，给定观测序列$O$和模型$\lambda$的情况下，计算概率$P(O|\lambda)$。 学习，已知观测序列$O$，估计模型$\lambda$参数，使得观测序列概率最大，通过极大似然来估计参数。 预测，也成为解码。已知模型和观测序列，求条件概率$P(I|O)$最大的状态序列。 计算概率​ 给定模型$\lambda=(A,B,\pi)$和观测序列$O=(o_1,o_2,…,o_T)$，计算观测序列$O$出现的概率$P(O|\lambda)$。 1、直接计算法​ 通过概率公式直接计算，列举出所有可能的长度为T的状态序列$I=(i_1,i_2,…,i_T)$，求各个状态序列$I$与观测序列$O$的联合概率$P(O,I|\lambda)$，然后对所有的状态序列求和，最后得到$P(O|\lambda)$。 ​ 状态序列$I=(i_1,i_2,…,i_T)$的概率是$$P(I|\lambda)=\pi_{i_i}A_{i_1i_2}…A_{i_{T-1}i_T}$$​ 对于固定的状态序列$I=(i_1,i_2,…,i_T)$，观测序列$O=(o_1,o_2,…,o_T)的概率为：$$P(O|I,\lambda) = b_{i_1o_1}b_{i_2o_2}…b_{i_To_T}$$​ 联合概率为：$$P(O,I|\lambda)=P(O|I,\lambda)P(I|\lambda)$$​ 对所有的状态序列$I$求和$$P(O|\lambda)=\sum_{I}P(O,I|\lambda)P(I|\lambda)$$​ 虽然上述计算在理论上可行，但实际上计算复杂度为$O(TN^T)$级别的。 2、前向算法​ 定义到$t$时刻部分观测序列为$o_1,o_2,…,o_t$且状态为$q_i$的概率为前向概率$$\alpha_t(i)=P(o_1,o_2,…,o_t,q_i|\lambda)$$​ 可以递推地求得前向概率$\alpha_t{i}$以及观测概率$P(O|\lambda)$。 算法： （1）初始值$$\alpha_1(i)=\pi_ib_{io_1}$$（2）递推$$\alpha_{t+1}(i)=[\sum_{j=1}^N\alpha_t(j)A_{j,i}]b_{io_{t+1}}$$（3）终止$$P(O|\lambda)=\sum_{i=1}^N\alpha_T(i)$$​ 使用此种方法进行计算时，每一步通过使用上一步得到的$N$个概率值，计算当前步的$N$个概率，复杂度降低到了$O(N^2T)$。 3、后向算法（其实只是变成了由后往前递推）​ 定义后向概率为:$$\beta_t(i)=P(o_{t+1},o_{t+2},…,o_{T}|i_t=q_i,\lambda)$$​ 算法：$$\beta_T(i)=1\\beta_t(i)=\sum_{j=1}^NA_{ij}b_{jo_{t+1}}\beta_{t+1}(j)\P(O|\lambda)=\sum_{i=1}^N\pi_ib_{io_1}\beta_1(i)$$ 4、 一些概率和期望值的计算​ 通过使用前项概率和后向概率可以有效地得到一些概率计算公式。$$\gamma_t(i)=P(i_t=q_i|O,\lambda)=\frac{\alpha_t(i)\beta_t(i)}{P(O|\lambda)}\\xi_t(i,j)=P(i_t=q_i,i_{t+1}=q_j|O,\lambda)=\frac{\alpha_t(i)A_{ij}b_{jo_{t+1}}\beta_{t+1}(j)}{\sum_{i=1}^N\sum_{j=1}^NP(i_t=q_i,i_{t+1}=q_j|O,\lambda)}$$ 学习算法1、有监督​ 统计频次计算概率转移矩阵$A$与概率发射矩阵$B$即可。 2、无监督(EM)​ 如果训练数据中只包含$S$个长度为$T$的观测序列，那么此时HMM转变为了一个含有隐变量的概率模型$$P(O|\lambda)=\sum_IP(O,I|\lambda)P(I|\lambda)$$​ 而隐变量模型的学习可以通过EM算法来实现。 略 预测算法1、近似算法​ 即贪心算法，在每个时间步均选择当前步最有可能出现的状态$i^*_t$，从而得到一个装态序列，并将其作为预测结果。$$i_t^*=arg\max_{N\geq i \geq 1}[\gamma_t(i)]$$ 2、维特比算法 Viterbi​ viterbi算法的本质属于动态优化，在每个时间步，计算所有由上一步各节点保留的最佳路径到该时间步各节点的路径，并且每个节点均只保留最佳的路径并记录该节点。直到到达最终的节点，选择概率最高的节点倒回去将该路径的节点集合最为最优解。 ​ 定义变量： ​ 在时刻$t$状态为$i$的所有单个路径中概率最大值$\delta_t(i)$$$\delta_t(i)=\max_{i_1,i_2,…,i_{t-1}}P(i_t=i,i_{t-1},…,i_1,o_t,…,o_1|\lambda)\\delta_{t+1}(i)=\max_{N\geq j\geq 1}[\delta_t(j)A_{ij}]b_{io_{t+1}}$$​ 在时刻$t$状态为$i$的所有单个路径中概率最大的路径的第$t-1$个结点为$$\psi_t(i)=arg \max_{N\geq j\geq 1}[\delta_{t-1}(j)A_{ij}]$$维特比算法 1、初始化$$\delta_1(i)=\pi_ib_{io_1}\\psi_1(i)=0$$2、递推$$\delta_{t+1}(i)=\max_{N\geq j\geq 1}[\delta_t(j)A_{ij}]b_{io_{t+1}}\\psi_t(i)=arg \max_{N\geq j\geq 1}[\delta_{t-1}(j)A_{ij}]$$3、终止$$P^=\max_{N \geq i \geq 1}\delta_T(i)\i^T=arg\max{N \geq i \geq 1}[\delta_T(i)]$$4、回溯$$i^t = \psi{t+1}(i^_{t+1})$$最终得到最优路径$i^=(i^_1,i^_2,…,i^_T)$。]]></content>
      <tags>
        <tag>概率图模型</tag>
        <tag>序列标注</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数值优化算法]]></title>
    <url>%2F2019%2F08%2F17%2F%E6%95%B0%E5%80%BC%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[梯度下降（最速下降）原理介绍假设$f(x)$是$\mathcal{R}^n$上具有一阶$\textbf{连续偏导数}$的函数，要求解$\textbf{无约束最优化问题}$$$min_{x\in \mathcal{R}^n}f(x)$$梯度下降法通过选取适当的初始值$x^{(0)}$，不断迭代，每次迭代是让$x$朝着当前最小的负梯度方向变化，从而减小函数值。 由于$f(x)$具有一阶连续偏导数 ，假定第$k$次迭代值为$x^{(k)}$，将$f(x)$在$x^{(k)}$处进行泰勒展开$$f(x)=f(x^{(k)})+g_k^T(x-x^{(k)})\g_k = g(x^{(k)})=\nabla f(x^{(k)})$$更新$x$值$$x^{(k+1)}\gets x^{(k)}+\lambda_k p_k$$其中$p_k$是搜索方向，即负梯度方向，$p_k=-\nabla f(x^{(k)})$，$\lambda_k$是搜索步长，由$\textbf{一维搜索确定}$，即$$f(x^{(k)}+\lambda_kp_k)=\min_{\lambda\geq0}f(x^{(k)}+\lambda_kp_k)$$ 例子$$f(x,y)=(1-x)^2+100(y-x^2)^2$$ 容易求得$$\frac{\partial f(x,y)}{\partial x}=-2(1-x)+200(y-x^2)(-2x)\\frac{\partial f(x,y)}{\partial y}=-2(1-x)+200(y-x^2)(-2x)$$ 12345678910111213141516171819202122232425262728import numpy as npdef cal_f(x1,x2): return (1 - x1) ** 2 + 100 * (x2 - x1 ** 2) ** 2def cal_prax(x1, x2): return -2 + 2 * x1 - 400 * (x2 - x1 ** 2) * x1def cal_pray(x1, x2): return 200 * (x2 - x1 ** 2)def for_rosenbrock_func(max_iter_count=100000, step_size=0.001): pre_x = np.zeros((2,), dtype=np.float32) loss = 10 iter_count = 0 while loss &gt; 0.001 and iter_count &lt; max_iter_count: error = np.zeros((2,), dtype=np.float32) error[0] = cal_prax(pre_x[0], pre_x[1]) error[1] = cal_pray(pre_x[0], pre_x[1]) for j in range(2): pre_x[j] -= step_size * error[j] loss = cal_f(pre_x[0], pre_x[1]) # 最小值为0 print("iter_count: ", iter_count, "the loss:", loss) iter_count += 1 return pre_xprint(for_rosenbrock_func()) 改进的尺度迭代法牛顿法拟牛顿法12]]></content>
      <categories>
        <category>优化</category>
      </categories>
      <tags>
        <tag>数值优化</tag>
        <tag>凸优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ReNN: Rule embedded neural network]]></title>
    <url>%2F2019%2F08%2F16%2FReNN-Rule-embedded-neural-network%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[BatchNorm]]></title>
    <url>%2F2019%2F07%2F30%2FBatchNorm%2F</url>
    <content type="text"><![CDATA[BatchNorm 中的坑训练和测试中的不一致性$$ \mu_{B}, \sigma_{B}^{2}=\text { mean, } \operatorname{var}(x, \text { axis }=[N, H, W])$$ at training time:（EMA）$$\begin{array}{l}{ \hat{x}=\frac{x-\mu_{B}}{\sigma_{B}}} \ { \mu_{E M A} \leftarrow \lambda \mu_{E M A}+(1-\lambda) \mu_{B}} \ { \sigma_{E M A}^{2} \leftarrow \cdots}\end{array}$$at test time:(no concept of batch)$$\hat{x}=\frac{x-\mu_{E M A}}{\sigma_{E M A}}$$当测试时的均值方差不能很好地拟合训练训练数据时，batchnnorml就会失去效果。 $\lambda$的取值，过大或者过小均不行 当EMA失败时往往体现出overfitting。 EMA永远是一个有偏估计，我们需要真正的average！ Precise-BatchNorm 停止训练，直接计算真正的EMA参数值。但是会导致时间增加，而且不能像EMA那样边训练边估计参数。 实现方法： 直接固定模型，走很多个iteration算一个真正的average 停止训练，用很大的lamda参数 BatchNorm与Learning_Rate理论上来说batch_norm增加几倍，learning_rate也因该增加相应的倍数。 batchnorm的batchsize与网络的batch_size多卡训练时，每个卡的batch_size和batchnorm的参数是自己固定的。 NBS controls regularization strength]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>正则化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LSTM and GRU]]></title>
    <url>%2F2019%2F07%2F29%2FLSTM-and-GRU%2F</url>
    <content type="text"><![CDATA[##1.LSTM ###1.1 LSTM介绍]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>rnn</tag>
        <tag>nlp</tag>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Pytorch实现Pointer-Generator]]></title>
    <url>%2F2019%2F07%2F23%2F%E4%BD%BF%E7%94%A8Pytorch%E5%AE%9E%E7%8E%B0Pointer-Generator%2F</url>
    <content type="text"><![CDATA[### Pointer-generator 介绍Pointer-Generator: 于ACL2017提出，是一种经典的文本摘要抽取框架$\color{blue}{开源代码}$ Baseline-seq2seq seq2seq由编码器与解码器两部分组成。通过编码器将序列信息编码输出为一个隐藏状态$h_i$，然后通过解码器将其解码为$s_t$，同时在解码每一个时间步$t$时使用注意力机制来获取当前的上下文状态$h_t^{*}$。$$ \begin{aligned} e_{i}^{t} &amp;=v^{T} \tanh \left(W_{h} h_{i}+W_{s} s_{t}+b_{\mathrm{attn}}\right) \ a^{t} &amp;=\operatorname{softmax}\left(e^{t}\right) \h_{t}^{}&amp;=\sum_{i} a_{i}^{t} h_{i} \end{aligned}$$ 在解码段的每个时间步，通过当前状态$s_t$与上下文状态$h_t^{\}$通过两层线性层映射为词表分布$P_{vocab}$$$ P_{\text { vocab }}=\operatorname{softmax}\left(V^{\prime}\left(V\left[s_{t}, h_{t}^{*}\right]+b\right)+b^{\prime}\right)$$ 这样便得到了词表上的softmax概率分布，进而可以预测生成的词。在第$t$步的损失函数为$loss_t=-log P(w_t^{*})$，此时原输入序列的整体损失为：$$ \operatorname{loss}=\frac{1}{T} \sum_{t=0}^{T} \operatorname{loss}_{t}$$ Pointer-Generator Networks 在传统的seq2seq模型上增加了pointer-network的copy机制，对于每个词判断是要从原文中copy还是从登入词中根据概率生成，解决了原文中的未登录词问题。文章引入了一个权重$P_{Gen}$来判断词是生成的还是复制的。 通过在Baseline-seq2seq中得到的$s_t$和$h_t^{*}$，以及解码器端的输入$x_t$一起计算$P_{Gen}$：$$ P_{\mathrm{gen}}=\sigma\left(w_{h^{*}}^{T} h_{t}^{*}+w_{s}^{T} s_{t}+w_{x}^{T} x_{t}+b_{\mathrm{ptr}}\right)$$ 这样会扩充本来的单词表形成一个更大的单词表，预测概率变为:$$ P(w)=p_{\mathrm{gen}} P_{\mathrm{vocab}}(w)+\left(1-p_{\mathrm{gen}}\right) \sum_{i : w_{i}=w} a_{i}^{t}$$ 其中$\alpha_i^t$表示原文档中的词。我们可以看到解码器一个词同时考虑了其输入生成还是拷贝的可能。当一个词不出现在常规词表中其概率$P_{vocab}$为0，反之该词不出现在文档中时$\sum_{i : w_{i}=w} a_{i}^{t}$为0。 $\color{red}{这样的概率限制实际上是如何实现的呢？}$ Coverage Mechanism 将先前的时间步的注意力权重加到一起得到覆盖向量$c^t$，用先前的注意力权重来影响当前的注意力权重，避免生成重复的文本。$$ c^{t}=\sum_{t^{\prime}=0}^{t-1} a^{t^{\prime}}\ e_{i}^{t}=v^{T} \tanh \left(W_{h} h_{i}+W_{s} s_{t}+\color{red}{w_{c} c_{i}^{t}}+b_{\mathrm{attn}}\right)$$ 同时注意为coverage vector添加损失函数:$$ cvtloss_{t}=\sum_{i} \min \left(a_{i}^{t}, c_{i}^{t}\right)$$ 这样保证了$cvtloss_{t} \leq \Sigma_{i} a_{i}^{t}=1$是一个有界的量，最终loss为:$$ \operatorname{loss}{t}=-\log P\left(w{t}^{*}\right)+\lambda \sum \min \left(a_{i}^{t}, c_{i}^{t}\right)$$ 分析一下，coverage loss为了使损失值最小，目的是使得$\sum c_i^t \leq 1$,这样保证了对于每个时间步$t$，其对应的覆盖向量$c^t$始终与其他状态表示维持在统一尺度上，不会影响计算。 具体实现 相关额外知识学习shell 中 -u对于print和error两种打印来说，print是有缓存的，累计到一定程度才会打印出来，而error是直接打印在屏幕上。 使用-u强制后面命令的输出直接打印出来 *与**python中 *代表任意多的参数，是一个tuple ** 则代表一个任意长度的dict getattrgetattr(x,”y”)等价于x.y picklepickle.dump() 将python对象转为序列化写入文件中 pickle.load() 将文件读取为对象 通过设置参数protocols=0，以文本形式序列化；或是protocols=1,2 ，以二进制形式序列化。现在貌似默认是4。 torch相关 lstmcell是组成LSTM的单元，当需要逐步解码时，就需要我们一个个单元来写前项传递过程。 nn.parameters()不同于variable parameters在Model中写入是会被自动添加进model的parameters列表中，自动计算梯度更新。parameters的require_grad默认是开启的，反之variable是关闭的。]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>nlp</tag>
        <tag>pytorch</tag>
        <tag>coding</tag>
        <tag>summaries</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Neural_Network_Initialization]]></title>
    <url>%2F2019%2F07%2F19%2FNeural-Network-Initialization%2F</url>
    <content type="text"><![CDATA[# 简介对于神经网络这种复杂非凸问题来说，初始化是非常重要的，对于不同的场景应当选择适合的初始化方法。以下介绍常用的初始化方法。 0初始化对于convex optimization问题来说，0初始化便可以达到很好的效果，但是这对于神经网络来说却是一种极为不利的方法，如果使用0初始化，则对应的每个神经元的参数都将是一致的，那么每次通过损失值梯度回传的更新参数也都是一致的，高度对称的权重使得神经网络失去了其最为重要的自动发掘特征的能力。 随机初始化目前最为常用的是随机初始化，但是针对不同问题需要选择合适的分布，不然同样会影响网络的性能。 假定我们有一个以tanh为激活函数的神经网络，对于其参数我们使用均值为0，方差为0.01的高斯分布。创建一个10层的神经网络，则每一层的输出值分布直方图如下： 实现代码： 123456789101112131415161718192021222324252627282930313233343536373839import tensorflow as tfimport numpy as npimport matplotlib.pyplot as plt%matplotlib inlinegraph = tf.Graph()with graph.as_default(): data = tf.constant(np.random.randn(2000, 800).astype('float32')) layer_sizes = [800 - 50 * i for i in range(0,10)] num_layers = len(layer_sizes) fcs = [] for i in range(0, num_layers - 1): X = data if i == 0 else fcs[i - 1] node_in = layer_sizes[i] node_out = layer_sizes[i + 1] W = tf.Variable(np.random.randn(node_in, node_out).astype('float32'))/np.sqrt(node_in) #W = tf.Variable(np.random.randn(node_in, node_out).astype('float32'))# * 0.01 # W = tf.Variable(np.random.randn(node_in, node_out).astype('float32')) fc = tf.matmul(X, W)# fc = tf.contrib.layers.batch_norm(fc, center=True, scale=True,# is_training=True) fc = tf.nn.tanh(fc) fcs.append(fc) with tf.Session(graph=graph) as sess: sess.run(tf.global_variables_initializer()) print('input mean &#123;0:.5f&#125; and std &#123;1:.5f&#125;'.format(np.mean(data.eval()), np.std(data.eval()))) for idx, fc in enumerate(fcs): print('layer &#123;0&#125; mean &#123;1:.5f&#125; and std &#123;2:.5f&#125;'.format(idx+1, np.mean(fc.eval()), np.std(fc.eval()))) plt.figure(figsize=(18,6)) for idx, fc in enumerate(fcs): plt.subplot(1, len(fcs), idx+1) plt.hist(fc.eval().flatten(), 30, range=[-1,1]) 随着层数的增加，很明显可以查看出输出值迅速向0靠拢，后面的层输出几乎全是0，通过反向传播得到的梯度也就变成了0，使得神经网络难以继续优化下去。 反之，若是我们将方差调大，变成1，输出如下： 为了解决这个问题，Glorot和Bengio在2010提出了Xavier初始化方法。 Xavier Initialization对于神经网络，我们希望他的输入空间和输出空间是同一个分布（一般用方差来衡量）。如果输入空间过于稀疏而输出空间过于稠密，那么通过反向传播得到的损失函数所返回的梯度就会变得很小使得网络难以训练；反之则会导致梯度爆炸。 在神经网络中层与层之间的传递主要是线性组合的形式：$$Z = \sum_{i=1}^{n}w_ix_i \tag{1.1}$$方差$$Var(w_ix_i)=Var(w_i)Var(x_i)+E^2(w_i)Var(x_i)+E^2(x_i)Var(w_i)\tag{1.2}$$ 推导 已知$Var(x)=E(x^2)-E^2(x)$$$Var(xy)=E(x^2y^2)-E^2(xy)$$由于$x$与$y$相互独立$$\begin{split}Var(xy)&amp;=E(x^2)E(y^2)-E^2(x)E^2(y)\&amp;=(Var(x)+E^2(x))(Var(y)+E^2(y))-E^2(x)E^2(y)\&amp;=Var(x)Var(y)+E^2(x)Var(y)+E^2(y)Var(x)\end{split}$$ 通过假定$E(w_i)$与$E(x_i)$均为0（这个可以通过batch normalization对每一层重新调整分布做到，事实上影响不大），我们有$$Var(w_ix_i)=Var(w_i)Var(x_i)\tag{1.3}$$因为假定$w_i与x_i$均服从独立同分布假设（所有机器学习的通用假设），$Var(x_i)=Var(x)$，最终：$$Var(z)=nVar(x)Var(w)\tag{1.4}$$要保持输入$x$与输出的$z$方差不变，使$w$得方差为1即可。从正向和反向两个角度来看，$n_{in}$与$n_{out}$是不同的，此处对其取平均值，得到$w$方差表达式：$$Var(w)=\frac{2}{n_{in}+n_{out}}\tag{1.5}$$假定$w$为均匀分布，均匀分布对应的方差为$$var(w)=\frac{(a-b)^2}{12}\tag{1.6}$$推出$w$的分布为:$$w\sim U[-\sqrt{\frac{6}{n_{in}+n_{out}}},\sqrt{\frac{6}{n_{in}+n_{out}}}]\tag{1.7}$$这便是Xavier初始化方法。 同样，我们使用代码对其进行验证： 可以看出效果非常的好，即使是在第十层也维持了良好的分布。 但是Xavier是在线性变换的基础上提出来的，上述的实验也是建立在激活函数为tanh的情况下，理论上来说Xavier对于非线性激活函数是不具有普适性的，那么我们尝试将激活函数替换为RELU再次进行实验： 果然，一开始效果还可以，后来就基本全部接近于0了。 为了解决Relu激活函数的初始化问题，Kaiming He大佬与2015年提出了一种新的初始化方法，可以帮助激活函数为Relu的神经网络获得良好的初始化，称之为He初始化。 He Initialization该初始化方法主要是针对卷积网络做的分析，首先对于卷积网络的每一层，我们有:$$y_l = w_l x_l + b_l\tag{2.1}$$$x_l$的维度为$k^2c\times1$，表示图像中一块$k\times k$并且包含$c$个通道的区域，即卷积操作时对应的输入区域，我们为方便后面的表达令$n=k^2c$；$w_l$的维度为$n\times d$，表示为$d$个卷积核；最后得到对应一个pixel位置上的$d$个通道的值就是$y_l \in \mathcal{R}^{d\times 1}$。同时对于整个网络来说，$c_l=d_{l-1}$。 对上式求方差，假定$w_l$与$x_l$相互独立且两者均独立同分布：$$Var(y_l)=n_lVar(w_lx_l)\tag{2.2}$$假定$w_l$是zero-mean，原因见上一节，公式推导也见上一节。$$Var(y_l)=n_lVar(w_l)E(x_l^2)\tag{2.3}$$由于RELU激活函数的性质，$x_l=max(0,y_{l-1})$，因此$E(x_l^2)\neq Var(x_l)$，假定我们使得$w_l$是一个关于0对称的分布，同时$y_l$也是一个关于0对称的分布，这会导致$$E(x_l^2)=\frac{1}{2}Var(y_{l-1})\tag{2.4}$$$y_{l-1}$作为上一层的输出，在通过激活层RELU函数时，由于$y_l$关于0对称，一半的信息直接变为0，因此缩小为原来的$\frac{1}{2}$。 将2.4式代入2.3式中:$$\begin{split}Var\left[y_{l}\right]&amp;=\frac{1}{2} n_{l} Var\left[w_{l}\right] Var\left[y_{l-1}\right]\end{split}\tag{2.5}$$ $$\operatorname{Var}\left[y_{L}\right]=\operatorname{Var}\left[y_{1}\right]\left(\prod_{l=2}^{L} \frac{1}{2} n_{l} \operatorname{Var}\left[w_{l}\right]\right)\tag{2.6}$$ 为了维持输入输出在同一个分布上，便需要满足$$\frac{1}{2} n_{l} \operatorname{Var}\left[w_{l}\right]=1, \quad \forall l\tag{2.7}$$因此直接每一层按照$w_l \sim \mathcal{N}(0,\sqrt{2/n_l})$的分布随机初始化即可。 同理，反向传播时最终得到的结论是一致的。唯一需要注意的是对于第一层，由于没有RELU激活函数，方差并不会变成一半，需要单独拿出来进行初始化。还有对于通过前向和反向推出的两个结果来说，使用任意一种均可，都可以使其收敛，套用原文中的一句话“如果初始化适当的缩放了反向传播的信号，那么这种缩放也会体现在正向传播上，反之亦然。” 再次通过代码验证效果： 相对于之前来说效果好了很多。 正交初始化Orthogonal Initialization主要用于循环神经网络的初始化问题中。 对于循环神经网络，梯度爆炸和梯度消失使得其难以训练，而梯度爆炸和消失的本质在于同一个矩阵在每个时间步都参与了矩阵相乘，本质是特征值得爆炸。通过正交初始化使得其更新矩阵的特征值均为1，让矩阵在多次相乘后特征值仍然保持在稳定的状况下。目前LSTM或是GRU基本都使用SVD分解来完成正交初始化。 $\color{red}{事实上这个方法也不是被完全认可，一部分人持反对意见，尚无定论。}$ Batch NormalizationBN更多是作为一种正则化方法来讲的，此处只是提一下，因为它与He、Xavier、正交初始化的核心思想都是保持数据在层与层之间传播时分布保持不变。 参考Explaining and illustrating orthogonal initialization for recurrent neural networks Delving Deep into Rectififiers：Surpassing Human-Level Performance on ImageNet Classifification Understanding the diffificulty of training deep feedforward neural networks PS:反向传播那一段的公式latex本地没问题，传上去一直出问题，只能截图，吐血。]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>初始化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MCMC-1-Markov-Chain]]></title>
    <url>%2F2019%2F07%2F19%2FMCMC-2-Markov-Chain%2F</url>
    <content type="text"><![CDATA[马尔科夫链概述马尔科夫链假设每一个时间步$t$的状态$X_t$的状态仅依赖于上一个时间步的状态$X_{t-1}$。用公式表达就是：$$P\left(X_{t+1} | \ldots X_{t-2}, X_{t-1}, X_{t}\right)=P\left(X_{t+1} | X_{t}\right)$$对于一个马尔科夫链来说，只要我们能够求出任意两个状态之间的转换概率，那么随着马尔科夫链的不断迭代，其最终状态的概率必定收敛。（前提是各转移概率不为0，也就是说每个状态都可以转换为任意状态。） 举一个列子： 上图是一个股票市场的马尔科夫链，共有三种状态，牛市（Bull market）, 熊市（Bear market）和横盘（Stagnant market） ，定义牛市为0，熊市为1，横盘为2，矩阵$P_{ij}$表示从状态$i$转移到状态$j$的概率。最终我们获得马尔科夫状态转移矩阵如下：$$P=\left(\begin{array}{ccc}{0.9} &amp; {0.075} &amp; {0.025} \ {0.15} &amp; {0.8} &amp; {0.05} \ {0.25} &amp; {0.25} &amp; {0.5}\end{array}\right)$$接下来我们使用代码验证其必定收敛的性质： 12 模型状态概率最终会收敛于[ 0.625 0.3125 0.0625]，而且事实上无论你怎么初始化状态概率，模型最终都会收敛到这个状态。 同时，对于一个确定的状态转移矩阵$P$，它的n次幂$P^n$对应的状态概率也会收敛到同样的稳定分布。 基于马尔科夫链进行采样如果我们能够得到一个分布对应的马尔科夫状态转移矩阵，我们就能采样出这个平稳分布的样本集。 任意选择一个初始分布$\pi_0(x)$，如高斯分布，对其进行采样获得样本$x_0$，基于状态转移条件概率$P(x|x_0)$采样状态值$x_1$，如此重复，当达到一定次数$n_1$时，我们便可以假定分布已经收敛到平稳分布，再重复$n_2$次，获得的$(x_{n_1}，x_{n_1+1},…x_{n_1+n_2})$即可视作我们的样本集，$n_2$为样本集中样本的数目。 小结使用马尔科夫链进行采样存在一个问题，如何获得转移概率矩阵$P$呢？详见下一节。 说明本文内容主要来自刘建平老师的博客https://www.cnblogs.com/pinard/p/6632399.html]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>统计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nlp task metric]]></title>
    <url>%2F2019%2F07%2F19%2Fnlp-task-metric%2F</url>
    <content type="text"><![CDATA[BELUbelu是机器翻译领域的指标，公式如下：$$B L E U=B P \cdot \exp \left(\sum_{n=1}^{N} w_{n} \log P_{n}\right)$$ $$B P=\left{\begin{array}{ll}{1} &amp; {\text { if } c&gt;r} \ {e^{1-r / c}} &amp; {\text { if } c \leq r}\end{array}\right.$$ 这个指标具体是如何运算的呢？ 列子： 候选译文（Predicted）：It is a guide to action which ensures that the military always obeys the commands of the party 参考译文（Gold Standard）1：It is a guide to action that ensures that the military will forever heed Party commands2：It is the guiding principle which guarantees the military forces always being under the command of the Party3：It is the practical guide for the army always to heed the directions of the party 首先计算$P_n$,若$n=4$，我们需要从$1gram$一直计算到$4gram$。$ngram$的计算方法是，对于候选译文中每个出现的n元组，统计其次数。对于每个三元组，定义max值为候选译文和参考译文中的最大值，定义min为候选译文和参考译文（除去最小的那个）的最小值。 最后将每个n元组的min值相加之和除以每个n元组的候选译文出现个数相加，得到的值即为$P_n$。 $w_i$为对应的$ngram$的权重，将所有$P_n$加权求和再取指数，最后乘上一个长度惩罚系数$BP$即可得到最终的belu值。 $BP$系数会惩罚过短的句子，它会自动得寻找尽可能跟标准翻译长度相近似的句子。]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>nlp</tag>
        <tag>评价指标</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mcmc:(1) 蒙特卡洛]]></title>
    <url>%2F2019%2F07%2F19%2FMCMC-1-Monte-Carlo-Method%2F</url>
    <content type="text"><![CDATA[MCMC——part1:蒙特卡洛搜索MCMC概述MCMC(Markov Chain Monte Carlo 马尔科夫链蒙特卡洛) 蒙特卡洛方法蒙特卡洛方法最早被用于求解一些不好计算的积分问题，如下图： 为了解决这个问题，我们假定使用一个值$f(x)$来代表区间$[a,b]$上所有值，此时积分的近似解就为:$$(b-a)f(x)$$使用一个值估计当然是不合理的，但是我们可以使用多个值来估计，假定我们对区间$[a,b]$进行n次采样，得到的采样$x_i$对应的被积函数值为$f(x_i)$，积分的近似解即为：$$\frac{b-a}{n} \sum_{i=0}^{n-1} f\left(x_{i}\right)$$但是这种情况是建立在$x$是均匀分布的情况下，而事实上大多数问题中的”$x$”都不会是服从均匀分布的。假定我们得到了$x$的概率分布函数$P(x)$，我们便可以求得更加准确的积分：$$\theta = \int_a^b f(x)dx = \int_a^b \frac{f(x)}{p(x)}p(x)dx\approx\frac{1}{n}\sum^{n-1}_{i=0}\frac{f(x_i)}{p(x_i)}$$ 基于概率分布进行采样假定我们已知$x$的概率分布，要使用Monte Carlo对$f(x)$积分进行估计，需要依据概率分布$p(x)$对$x$进行采样。对于常见的分布如正态分布、t分布等是可以很容易的通过已有的库获得的。但是对于一些不常见的分布，如何对其进行采样呢？ 接受-拒绝采样假定一个可以采样的分布，如高斯分布$q(x)$，称为proposal distribution。 设定一个常量$k$使得$p(x)$总在$kq(x)$的下方，如上图。 首先采样得到$q(x)$的一个样本$z_0$，然后从均匀分布$(0,kq(z_0))$中采样得到一个值$u$，如果$u$落在上方灰色区域则拒绝此次采样，否则接受此次采样，重复直到获得足够数目的样本。 试着分析一下这种做法，每次采样获得的样本接受概率如下:$$p(\text {accept})=\int \frac{\tilde{p}(z)}{k q(z)} q(z) d z=\frac{1}{k} \int \tilde{p}(z) d z$$下面我们尝试使用拒绝接受采样对分布$$\tilde{p}(z)=0.3 \exp \left(-(z-0.3)^{2}\right)+0.7 \exp \left(-(z-2)^{2} / 0.3\right)$$进行采样。归一化常数为1.2113，参考分布为$Gussian(1.4,1.2)$。 python代码实现 1234567891011121314151617181920212223242526import matplotlib.pyplot as pltimport numpy as np#绘制目标分布def cal_px(x): return (0.3*np.exp(-(x-0.3)**2) + 0.7* np.exp(-(x-2.)**2/0.3))/1.2113x = np.arange(-4.,6.,0.01)plt.plot(x,cal_px(x),color='r')#生成qz的分布size = int(1e+07)sigma = 1.2z = np.random.normal(loc=1.4,scale=sigma,size=size)qz = 1/(np.sqrt(2*np.pi)*sigma)*np.exp(-0.5*(z-1.4)**2/sigma**2)k = 2.5#再0到kq(z)之间均匀采样u = np.random.uniform(low = 0, high = k*qz, size = size)#从sample中选出符合条件的zpz = 0.3*np.exp(-(z-0.3)**2) + 0.7* np.exp(-(z-2.)**2/0.3)sample = z[pz &gt;= u]#绘制采样的图像plt.hist(sample,bins=150, normed=True, edgecolor='black')plt.show() 结果如下，可以看出效果还是非常好的： 一些问题 对于高维分布要找到合适的$q(x)$和$k$是非常困难的。 对于二维分布，一般得到的是其条件分布而非一般形式的$p(x,y)$，这时接受拒绝是无法使用的。 转载说明本文主要内容来自刘建平老师的文章，原文链接https://www.cnblogs.com/pinard/p/6625739.html]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>统计</tag>
        <tag>蒙特卡洛</tag>
      </tags>
  </entry>
</search>
